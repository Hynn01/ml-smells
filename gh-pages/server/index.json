[{"content":"Description Debugging is easier if the results are reproducible when developing ML systems. Also, reproducibility helps conduct studies based on previous models. Setting random seeds significantly contributes to the reproducibility of ML applications. There are several scenes that a random seed is involved. In Scikit-Learn, randomness is inherently involved in some estimators(e.g., Random Forest) and cross-validation splitters. If the random seed is not set, the random forest algorithm might provide a different result every time it runs, and the dataset split by cross-validation splitter will also be different next time it runs. In Pytorch and Numpy, it is also recommended to set global random seed first for reproducible result. Specifically, DataLoader in PyTorch needs the setting of random seed to ensure the data splitted and loaded in the same way every time running the code. In various grey literature, the importance of setting random seed is noted. Therefore, we suggest the developers set random seed explicitly during the development process whenever a possible random procedure is involved in the application.\nType Generic\nExisting Stage General\nEffect Reproducibility\nExample ### python in general import random + random.seed(0)  ### Tensorflow import tensoflow as tf + tf.random.set_seed(0)  ### PyTorch import torch + torch.manual_seed(0)  ### Scikit-Learn from sklearn.model_selection import KFold + rng = 0 - kf = KFold(random_state=None) + kf = KFold(random_state=rng)  ### NumPy import numpy as np + np.random.seed(0) Source: Paper Grey Literature  https://towardsdatascience.com/my-machine-learning-model-is-perfect-9a7928e0f604 https://github.com/IgorSusmelj/pytorch-styleguide  GitHub Commit Stack Overflow  https://stackoverflow.com/questions/57416925/best-practices-for-generating-a-random-seeds-to-seed-pytorch  Documentation  https://pytorch.org/docs/stable/notes/randomness.html  ","permalink":"https://hynn01.github.io/dslinter/code-smells/randomness-uncontrolled/","summary":"Description Debugging is easier if the results are reproducible when developing ML systems. Also, reproducibility helps conduct studies based on previous models. Setting random seeds significantly contributes to the reproducibility of ML applications. There are several scenes that a random seed is involved. In Scikit-Learn, randomness is inherently involved in some estimators(e.g., Random Forest) and cross-validation splitters. If the random seed is not set, the random forest algorithm might provide a different result every time it runs, and the dataset split by cross-validation splitter will also be different next time it runs.","title":"Randomness Uncontrolled"},{"content":"Description “In-place operation is an operation that directly changes the content of a given linear algebra, vector, matrices (Tensor) without making a copy.” Due to the nature of the in-place operation, the in-place APIs are easily misused. Developers sometimes forget to set the in-place parameter in APIs to true while not assigning the new result to a variable, causing potential silent bugs. The data is not updated in this way, but the developer thinks it is and might not be able to find where the bug is. For example, when using Pandas library, sometimes the developers do not assign the new result to a DataFrame without setting the in-place parameter to be true, causing the DataFrame not to be updated. In the TensorFlow dataset, we also found an example that the developer thought np.clip() is an in-place operation and used it without assigning it to a new variable.\nSome developers hold the view that in-place operation will save memory. However, in Pandas library, this is a misconception because the copy of the data is still created. In PyTorch, the in-place operation does save GPU memory, but it can potentially overwrite values required to compute gradients. Therefore, we suggest developers be careful with the in-place operation.\nType Generic\nExisting Stage Data Preparation\nEffect Error-prone\nExample ### NumPy import numpy as np zhats = [2, 3, 1, 0] - np.clip(zhats, -1, 1) + zhats = np.clip(zhats, -1, 1)  ### Pandas import pandas as pd df = pd.DataFrame([-1]) - df.abs() + df = df.abs() Source: Paper  MPA Haakman. 2020. Studying the Machine Learning Lifecycle and ImprovingCode Quality of Machine Learning Applications.  Grey Literature  https://towardsdatascience.com/in-place-operations-in-pytorch-f91d493e970e https://github.com/bamos/dcgan-completion.tensorflow/commit/e8b930501dffe01db423b6ca1c65d3ac54f27223  GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/in-place-apis-misused/","summary":"Description “In-place operation is an operation that directly changes the content of a given linear algebra, vector, matrices (Tensor) without making a copy.” Due to the nature of the in-place operation, the in-place APIs are easily misused. Developers sometimes forget to set the in-place parameter in APIs to true while not assigning the new result to a variable, causing potential silent bugs. The data is not updated in this way, but the developer thinks it is and might not be able to find where the bug is.","title":"In Place APIs Misused"},{"content":"Description \u0026ldquo;Vectorization is the process of converting an algorithm from operating on a single value at a time to operating on a set of values (vector) at one time.\u0026rdquo; ML applications are often data-intensive and need to apply an operation on a dataset. Therefore, it is better to adopt vectorized solution instead of iterating over data. As stated in the Pandas documentation : ”Iterating through pandas objects is generally slow. In many cases, iterating manually over the rows is not needed and can be avoided”. The built-in methods (e.g., join, groupby) in Pandas are vectorized. Thus, it is recommended to use Pandas built-in methods. Another advantage of using the vectorized solution is that code complexity is reduced, resulting in less prone-to-bugs code.\nType Generic\nExisting Stage Data Preparation\nEffect Efficiency\nExample ### Pandas import pandas as pd df = pd.DataFrame([1, 2, 3]) - result = [] - for index, row in df.iterrows(): - result.append(row[0] + 1) - result = pd.DataFrame(result) + result = df.add(1)  ### TensorFlow 2 import tensorflow as tf x = tf.random.uniform([500, 10]) - z = tf.zeros([10]) - for i in range(500): - z += x[i] + z = tf.reduce_sum(x, axis=0) Source: Paper  MPA Haakman. 2020. Studying the Machine Learning Lifecycle and ImprovingCode Quality of Machine Learning Applic  Grey Literature GitHub Commit  https://github.com/tensorflow/models/commit/90f63a1e1653bfa17fde8260a4aa20231b269b7d  Stack Overflow Documentation  https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#iteration  ","permalink":"https://hynn01.github.io/dslinter/code-smells/unnecessary-iteration/","summary":"Description \u0026ldquo;Vectorization is the process of converting an algorithm from operating on a single value at a time to operating on a set of values (vector) at one time.\u0026rdquo; ML applications are often data-intensive and need to apply an operation on a dataset. Therefore, it is better to adopt vectorized solution instead of iterating over data. As stated in the Pandas documentation : ”Iterating through pandas objects is generally slow. In many cases, iterating manually over the rows is not needed and can be avoided”.","title":"Unnecessary Iteration"},{"content":"Description Principle Component Analysis (PCA) is used for finding the components that maximize the data\u0026rsquo;s variation and reduce its dimensions, which is an essential data processing method. Scaling is pretty crucial to PCA because of the way the principal components are calculated. If one variable is on a larger scale than another, it will dominate the PCA procedure. Similarly, there are some other scaling-sensitive operations. Support Vector Machine (SVM), Stochastic Gradient Descent (SGD), Multi-layer Perceptron classifier, L1 and L2 regularization are all sensitive to feature scaling. To avoid bugs, whether feature scaling is added before these operations should be checked.\nType Generic\nExisting Stage Data Preparation\nEffect Efficiency\nExample ### Scikit-Learn PCA from sklearn.datasets import load_wine from sklearn.model_selection import train_test_split from sklearn.pipeline import make_pipeline from sklearn.decomposition import PCA from sklearn.naive_bayes import GaussianNB from sklearn.metrics import accuracy_score + from sklearn.preprocessing import StandardScaler  # Code source: Tyler Lanigan \u0026lt;tylerlanigan@gmail.com\u0026gt; # Sebastian Raschka \u0026lt;mail@sebastianraschka.com\u0026gt; # License: BSD 3 clause # Make a train/test split using 30% test size RANDOM_STATE = 42 features, target = load_wine(return_X_y=True) X_train, X_test, y_train, y_test = train_test_split( features, target, test_size=0.30, random_state=RANDOM_STATE ) # Fit to data and predict using pipeline - clf = make_pipeline(PCA(n_components=2), GaussianNB()) + clf = make_pipeline(StandardScaler(), PCA(n_components=2), GaussianNB()) clf.fit(X_train, y_train) pred_test = clf.predict(X_test) ac = accuracy_score(y_test, pred_test) ### Scikit-Learn SVC from sklearn.datasets import load_wine from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score from sklearn.svm import SVC + from sklearn.pipeline import make_pipeline + from sklearn.preprocessing import StandardScaler  # Make a train/test split using 30% test size RANDOM_STATE = 42 features, target = load_wine(return_X_y=True) X_train, X_test, y_train, y_test = train_test_split( features, target, test_size=0.30, random_state=RANDOM_STATE ) # Fit to data and predict using pipelined GNB and PCA - clf = SVC() + clf = make_pipeline(StandardScaler(), SVC()) clf.fit(X_train, y_train) pred_test = clf.predict(X_test) ac = accuracy_score(y_test, pred_test) Source: Paper Grey Literature  https://towardsdatascience.com/my-machine-learning-model-is-perfect-9a7928e0f604 https://ml.posthaven.com/machine-learning-done-wrong  GitHub Commit Stack Overflow  https://stackoverflow.com/questions/17455302/gridsearchcv-extremely-slow-on-small-dataset-in-scikit-learn/23813876#23813876  Documentation  https://scikit-learn.org/stable/modules/preprocessing.html https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-download-auto-examples-preprocessing-plot-scaling-importance-py  ","permalink":"https://hynn01.github.io/dslinter/code-smells/no-scaling-before-scaling-sensitive-operation/","summary":"Description Principle Component Analysis (PCA) is used for finding the components that maximize the data\u0026rsquo;s variation and reduce its dimensions, which is an essential data processing method. Scaling is pretty crucial to PCA because of the way the principal components are calculated. If one variable is on a larger scale than another, it will dominate the PCA procedure. Similarly, there are some other scaling-sensitive operations. Support Vector Machine (SVM), Stochastic Gradient Descent (SGD), Multi-layer Perceptron classifier, L1 and L2 regularization are all sensitive to feature scaling.","title":"No Scaling Before Scaling-sensitive Operation"},{"content":"Description \u0026ldquo;Data Leakage happens when the data you are using to train a machine learning algorithm happens to have the information you are trying to predict.\u0026rdquo; It results in overly optimistic performance during testing and poor performance in real-world usage. There are two main sources of data leakage: leaky predictors and a leaky validation strategy. Leaky predictors refer to the situation where some features updated or created after the target value is realized are included. This kind of data leakage can only be inspected at the data level rather than the code level. Leaky validation strategy refers to the scene where information from training data is getting mixed with validation data. This kind of pitfall can be avoided by checking the code carefully. One best practice in Scikit-Learn is to use Pipeline API to prevent data leakage.\nType Generic\nExisting Stage Data Preparation\nEffect Error-prone\nExample ### Scikit-Learn from sklearn.model_selection import train_test_split from sklearn.feature_selection import SelectKBest from sklearn.ensemble import GradientBoostingClassifier from sklearn.metrics import accuracy_score import numpy as np + from sklearn.pipeline import make_pipeline  n_samples, n_features, n_classes = 200, 10000, 2 rng = np.random.RandomState(42) X = rng.standard_normal((n_samples, n_features)) y = rng.choice(n_classes, n_samples) - X_selected = SelectKBest(k=25).fit_transform(X, y) - X_train, X_test, y_train, y_test = train_test_split(X_selected, y, random_state=42) - gbc = GradientBoostingClassifier(random_state=1) - gbc.fit(X_train, y_train) - y_pred = gbc.predict(X_test) + X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) + pipeline = make_pipeline(SelectKBest(k=25), GradientBoostingClassifier(random_state=1)) + pipeline.fit(X_train, y_train) + y_pred = pipeline.predict(X_test)  accuracy_score(y_test, y_pred) Source: Paper  MPA Haakman. 2020. Studying the Machine Learning Lifecycle and Improving Code Quality of Machine Learning Applications. (2020).  Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/43816718/keras-regression-using-scikit-learn-standardscaler-with-pipeline-and-without-pip/43816833#43816833  Documentation  https://scikit-learn.org/stable/common_pitfalls.html  ","permalink":"https://hynn01.github.io/dslinter/code-smells/data-leakage/","summary":"Description \u0026ldquo;Data Leakage happens when the data you are using to train a machine learning algorithm happens to have the information you are trying to predict.\u0026rdquo; It results in overly optimistic performance during testing and poor performance in real-world usage. There are two main sources of data leakage: leaky predictors and a leaky validation strategy. Leaky predictors refer to the situation where some features updated or created after the target value is realized are included.","title":"Data Leakage"},{"content":"Description Hyperparameters are ML algorithm parameters used to control the learning process and are usually determined before the actual process starts. Hyperparameters should be set and tuned because they improve prediction quality and reproducibility. Tuning hyperparameters can lead to higher prediction quality because the default parameters of the learning algorithm may not be optimal for a given data or problem, and may lead to local optima. These parameters directly control the behavior of the training algorithm and therefore have a significant impact on the performance of the model.\nThe second reason for defining hyperparameters for learning algorithms is that it improves reproducibility. While the default parameters of a machine learning library may be perfect for some time, these default parameters of the library may change in new versions of the library. In addition, setting all hyperparameters explicitly allows replicating the model in a different programming language. Therefore, it is easier to reproduce the results if hyperparameters are set.\nType Generic\nExisting Stage Data Preparation\nEffect Error-prone \u0026amp; Reproducibility\nExample ### Scikit-Learn from sklearn.cluster import KMeans - kmeans = KMeans() + kmeans = KMeans(n_clusters=8, random_state=0) + # Or, ideally: + kmeans = KMeans(n_clusters=8, + init=\u0026#39;k-means++\u0026#39;, n_init=10, + max_iter=300, tol=0.0001, + precompute_distances=\u0026#39;auto\u0026#39;, + verbose=0, random_state=0, + copy_x=True, n_jobs=1, + algorithm=\u0026#39;auto\u0026#39;)  ### PyTorch import torch import numpy as np from kmeans_pytorch import kmeans # data data_size, dims, num_clusters = 1000, 2, 3 x = np.random.randn(data_size, dims) / 6 x = torch.from_numpy(x) # kmeans - cluster_ids_x, cluster_centers = kmeans(X=x, num_clusters=num_clusters) + cluster_ids_x, cluster_centers = kmeans( + X=x, num_clusters=num_clusters, distance=\u0026#39;euclidean\u0026#39;, device=torch.device(\u0026#39;cpu\u0026#39;) + ) Source: Paper  MPA Haakman. 2020. Studying the Machine Learning Lifecycle and ImprovingCode Quality of Machine Learning Applications. (2020). Eric Breck, Shanqing Cai, Eric Nielsen, Michael Salib, and D Sculley. 2017. TheML test score: A rubric for ML production readiness and technical debt reduction.In2017 IEEE International Conference on Big Data (Big Data). IEEE, 1123–1132. Gopi Krishnan Rajbahadur, Gustavo Ansaldi Oliva, Ahmed E Hassan, and Juer-gen Dingel. 2019. Pitfalls Analyzer: Quality Control for Model-Driven DataScience Pipelines. In2019 ACM/IEEE 22nd International Conference on ModelDriven Engineering Languages and Systems (MODELS). IEEE, 12–22. Nargiz Humbatova, Gunel Jahangirova, Gabriele Bavota, Vincenzo Riccio, AndreaStocco, and Paolo Tonella. 2020. Taxonomy of real faults in deep learning sys-tems. InProceedings of the ACM/IEEE 42nd International Conference on SoftwareEngineering. 1110–1121.  Grey Literature GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/hyperparameter-not-explicitly-set/","summary":"Description Hyperparameters are ML algorithm parameters used to control the learning process and are usually determined before the actual process starts. Hyperparameters should be set and tuned because they improve prediction quality and reproducibility. Tuning hyperparameters can lead to higher prediction quality because the default parameters of the learning algorithm may not be optimal for a given data or problem, and may lead to local optima. These parameters directly control the behavior of the training algorithm and therefore have a significant impact on the performance of the model.","title":"Hyperparameter not Explicitly Set"},{"content":"Description Excessive hyperparameter precision is a potential risk for overtuning. Overtuning occurs if an overly high precision hyperparameter value allows the model to perform particularly well while values in close range of it do not. Further, the choice of such a hyperparameter might be uninterpretable to users, which leads to an untrustworthy result.\nType Generic\nExisting Stage Model Training\nEffect Error-prone\nExample ### Scikit-Learn from sklearn.naive_bayes import MultinomialN # Violated Code mnb = MultinomialNB(alpha = 0.1001) # Recommended Fix mnb = MultinomialNB(alpha = 0.1) Source: Paper Grey Literature  https://towardsdatascience.com/my-machine-learning-model-is-perfect-9a7928e0f604  GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/deprecated/excessive-hyperparameter/","summary":"Description Excessive hyperparameter precision is a potential risk for overtuning. Overtuning occurs if an overly high precision hyperparameter value allows the model to perform particularly well while values in close range of it do not. Further, the choice of such a hyperparameter might be uninterpretable to users, which leads to an untrustworthy result.\nType Generic\nExisting Stage Model Training\nEffect Error-prone\nExample ### Scikit-Learn from sklearn.naive_bayes import MultinomialN # Violated Code mnb = MultinomialNB(alpha = 0.","title":"Excessive Hyperparameter"},{"content":"Description Counterintuitive hyperparameters will also cause bugs. There are four posts on StackOverflow discussing where the bug in the program is, and it turns out that a large learning rate causes bugs. This implies that the developer should check whether the hyperparameters stay in the normal range when developing ML applications.\nType Generic\nExisting Stage Model Training\nEffect Error-prone\nExample # TensorFlow import tensorflow as tf # Violated Code optimizer = tf.train.GradientDescentOptimizer(0.01) # Recommended Fix optimizer = tf.train.GradientDescentOptimizer(0.001) Source: Paper Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/33641799/why-does-tensorflow-example-fail-when-increasing-batch-size https://stackoverflow.com/questions/43636736/tensorflow-weights-diverge-or-nan https://stackoverflow.com/questions/43948571/tensorflow-loss-becomes-nan https://stackoverflow.com/questions/46577203/tensorflow-issues  Documentation ","permalink":"https://hynn01.github.io/dslinter/deprecated/counterintuitive-hyperparameter/","summary":"Description Counterintuitive hyperparameters will also cause bugs. There are four posts on StackOverflow discussing where the bug in the program is, and it turns out that a large learning rate causes bugs. This implies that the developer should check whether the hyperparameters stay in the normal range when developing ML applications.\nType Generic\nExisting Stage Model Training\nEffect Error-prone\nExample # TensorFlow import tensorflow as tf # Violated Code optimizer = tf.","title":"Counterintuitive Hyperparameter"},{"content":"Description ML application training is memory-consuming, and thus, it is essential to free memory in time. Some APIs are provided to alleviate the run-out-of-memory issue in deep learning libraries. TensorFlow\u0026rsquo;s documentation notes that if the model is created in a loop, it is suggested to use clear\\_session() in the loop. Meanwhile, the GitHub repository \u0026ldquo;Pytorch best practice\u0026rdquo; recommends using .detach() to detach the tensor whenever possible. We suggest developers check whether they use these APIs to free the memory whenever possible in their code.\nType Generic\nExisting Stage Model Training\nEffect Memory Issue\nExample ### TensorFlow import tensorflow as tf # Violated Code for _ in range(100): + tf.keras.backend.clear_session()  model = tf.keras.Sequential([tf.keras.layers.Dense(10) for _ in range(10)]) Source: Paper Grey Literature  https://github.com/IgorSusmelj/pytorch-styleguide  GitHub Commit Stack Overflow Documentation  https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session https://stackoverflow.com/questions/42495930/tensorflow-oom-on-gpu  ","permalink":"https://hynn01.github.io/dslinter/code-smells/memory-not-freed/","summary":"Description ML application training is memory-consuming, and thus, it is essential to free memory in time. Some APIs are provided to alleviate the run-out-of-memory issue in deep learning libraries. TensorFlow\u0026rsquo;s documentation notes that if the model is created in a loop, it is suggested to use clear\\_session() in the loop. Meanwhile, the GitHub repository \u0026ldquo;Pytorch best practice\u0026rdquo; recommends using .detach() to detach the tensor whenever possible. We suggest developers check whether they use these APIs to free the memory whenever possible in their code.","title":"Memory not Freed"},{"content":"Description Some libraries provide APIs for developers to use the deterministic algorithm. Using deterministic algorithms is another effort that can be made to improve reproducibility. In PyTorch, it is suggested to set torch.use_deterministic_algorithms(True) when debugging. However, the application will perform slower if this option is set, so it is suggested not to use it in the deploy stage. Developers should be aware of this setting during the development process.\nType Generic\nExisting Stage Model Training\nEffect Reproducibility\nExample ### PyTorch import torch + torch.use_deterministic_algorithms(True) Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation  https://pytorch.org/docs/stable/notes/randomness.html  ","permalink":"https://hynn01.github.io/dslinter/code-smells/deterministic-algorithm-not-used/","summary":"Description Some libraries provide APIs for developers to use the deterministic algorithm. Using deterministic algorithms is another effort that can be made to improve reproducibility. In PyTorch, it is suggested to set torch.use_deterministic_algorithms(True) when debugging. However, the application will perform slower if this option is set, so it is suggested not to use it in the deploy stage. Developers should be aware of this setting during the development process.\nType Generic","title":"Deterministic Algorithm Not Used"},{"content":"Description Several posts on Stack Overflow talk about the bugs that are not easy to discover caused by the log parameter approaching zero. In this kind of program, the log function variable turns to zero and raises an error during the training process. However, the error\u0026rsquo;s stack trace did not directly point to the line of code that the bug exist. This kind of problem is not easy to debug and might take a long training time to find. Therefore, the developer should check the log parameter and may add a very small number to the log parameter in the code before running it. It will save time and effort if the developer could identify this smell before the code run into errors.\nType Generic\nExisting Stage Model Training\nEffect Error-prone\nExample ### TensorFlow 1.x from tensorflow.examples.tutorials.mnist import input_data import tensorflow as tf mnist = input_data.read_data_sets(\u0026#34;MNIST_data/\u0026#34;, one_hot=True) sess = tf.InteractiveSession() def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial) def bias_Variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial) def conv2d(x, W): return tf.nn.conv2d(x, W, strides=[1,1,1,1],padding=\u0026#34;SAME\u0026#34;) def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1],padding=\u0026#34;SAME\u0026#34;) x = tf.placeholder(tf.float32, [None, 784]) y_ = tf.placeholder(tf.float32, [None, 10]) x_image = tf.reshape(x, [-1, 28, 28, 1]) W_conv1 = weight_variable([5,5,1,32]) b_conv1 = bias_Variable([32]) h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) h_pool1 = max_pool_2x2(h_conv1) W_conv2 = weight_variable([5,5,32,64]) b_conv2 = bias_Variable([64]) h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2) h_pool2 = max_pool_2x2(h_conv2) W_fc1 = weight_variable([7*7*64,1024]) b_fc1 = bias_Variable([1024]) h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64]) h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1) keep_prob = tf.placeholder(tf.float32) h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob) W_fc2 = weight_variable([1024,10]) b_fc2 = bias_Variable([10]) y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2) - cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_conv),reduction_indices=[1])) + cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(tf.clip_by_value(y_conv,1e-10,1.0)),reduction_indices=[1])) train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) tf.global_variables_initializer().run() for i in range(20000): batch = mnist.train.next_batch(50) if i % 100 == 0: train_accuracy = accuracy.eval(feed_dict = {x:batch[0] , y_:batch[1], keep_prob: 1.0}) print(\u0026#34;step %d,train accuracy %g\u0026#34;%(i,train_accuracy)) train_step.run(feed_dict = {x:batch[0] , y_:batch[1], keep_prob: 0.5}) print(\u0026#34;test accuracy %g\u0026#34;%accuracy.eval(feed_dict = {x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0})) Source: Paper  Nargiz Humbatova, Gunel Jahangirova, Gabriele Bavota, Vincenzo Riccio, AndreaStocco, and Paolo Tonella. 2020. Taxonomy of real faults in deep learning sys-tems. InProceedings of the ACM/IEEE 42nd International Conference on SoftwareEngineering. 1110–1121. Yuhao Zhang, Yifan Chen, Shing-Chi Cheung, Yingfei Xiong, and Lu Zhang. 2018.An empirical study on TensorFlow program bugs. InProceedings of the 27th ACMSIGSOFT International Symposium on Software Testing and Analysis. 129–140.  Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/33712178/tensorflow-nan-bug https://stackoverflow.com/questions/33699174/tensorflows-relugrad-claims-input-is-not-finite https://stackoverflow.com/questions/39487825/tensorflow-convolutionary-net-grayscale-vs-black-white-training https://stackoverflow.com/questions/35078027/implement-mlp-in-tensorflow  Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/missing-the-mask-of-invalid-value/","summary":"Description Several posts on Stack Overflow talk about the bugs that are not easy to discover caused by the log parameter approaching zero. In this kind of program, the log function variable turns to zero and raises an error during the training process. However, the error\u0026rsquo;s stack trace did not directly point to the line of code that the bug exist. This kind of problem is not easy to debug and might take a long training time to find.","title":"Missing the Mask of Invalid Value"},{"content":"Description While None == None evaluates to True, numpy.nan == numpy.nan evaluates to False. As Pandas treats None like numpy.nan for simplicity and performance reasons, a comparison of DataFrame elements with numpy.nan always return False . Therefore, developers need to be careful when using the NaN comparision in Numpy and Pandas. Otherwise, it may lead to unintentional behavior in the code.\nType API Specific\nExisting Stage Data Preparation\nEffect Error-prone\nExample ### Pandas \u0026amp; NumPy import pandas as pd - import numpy as np  df = pd.DataFrame([1, None, 3]) - df_is_nan = df == np.nan + df_is_nan = df.isna() Source: Paper  MPA Haakman. 2020. Studying the Machine Learning Lifecycle and ImprovingCode Quality of Machine Learning Application. (2020).  Grey Literature GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/nan-equality-misused/","summary":"Description While None == None evaluates to True, numpy.nan == numpy.nan evaluates to False. As Pandas treats None like numpy.nan for simplicity and performance reasons, a comparison of DataFrame elements with numpy.nan always return False . Therefore, developers need to be careful when using the NaN comparision in Numpy and Pandas. Otherwise, it may lead to unintentional behavior in the code.\nType API Specific\nExisting Stage Data Preparation\nEffect Error-prone","title":"Nan Equality Misused"},{"content":"Description Context In Pandas, df[\u0026quot;one\u0026quot;][\u0026quot;two\u0026quot;] and df.loc[:,(\u0026quot;one\u0026quot;,\u0026quot;two\u0026quot;)] give the same result. df[\u0026quot;one\u0026quot;][\u0026quot;two\u0026quot;] is called chain indexing.\nProblem Using chain indexing may cause performance issues as well as prone-to-bug code. For example, when using df[\u0026quot;one\u0026quot;][\u0026quot;two\u0026quot;], Pandas see this operation as two events: call df[\u0026quot;one\u0026quot;] first and call [\u0026quot;two\u0026quot;] based on the result the previous operation gets. On the contrary, df.loc[:,(\u0026quot;one\u0026quot;,\u0026quot;two\u0026quot;)] only perform a single call. In this way, the second approach can be significantly faster than the first one. Furthermore, assigning to the product of chain indexing has inherently unpredictable results. Since Pandas makes no guarantees on whether df[\u0026quot;one\u0026quot;] will return a view or a copy, the assignment may fail.\nSolution Developers using Pandas should avoid using chain indexing.\nType API Specific\nExisting Stage Data Preparation\nEffect Error-prone \u0026amp; Efficiency\nExample ### Pandas import pandas as pd df = pd.DataFrame([[1,2,3],[4,5,6]]) col = 1 x = 0 - df[col][x] = 42 + df.loc[x, col] = 42 Source: Paper Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/22491628/extrapolate-values-in-pandas-dataframe/35959909#35959909 https://stackoverflow.com/questions/53806570/why-does-one-use-of-iloc-give-a-settingwithcopywarning-but-the-other-doesnt/53807453#53807453  Documentation  https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-view-versus-copy  ","permalink":"https://hynn01.github.io/dslinter/code-smells/chain-indexing/","summary":"Avoid using chain indexing in Pandas.","title":"Chain Indexing Misused"},{"content":"Description When converting DataFrame to NumPy array, it is better to use df.to\\_numpy() than df.values(). As noted in a post, df.values() has inconsistency problem. With .values it is unclear whether the returned value would be the actual array, some transformation of it, or one of the Pandas custom arrays. However, .values is not deprecated yet. Although the library developers note it as a warning in the documentation, it does not log a warning or error when compiling if we use .value.\nType API Specific\nExisting Stage Data Preparation\nEffect Consistency\nExample ### NumPy \u0026amp; Pandas import numpy as np import pandas as pd index = [1, 2, 3, 4, 5, 6, 7] a = [np.nan, np.nan, np.nan, 0.1, 0.1, 0.1, 0.1] b = [0.2, np.nan, 0.2, 0.2, 0.2, np.nan, np.nan] c = [np.nan, 0.5, 0.5, np.nan, 0.5, 0.5, np.nan] df = pd.DataFrame({\u0026#39;A\u0026#39;: a, \u0026#39;B\u0026#39;: b, \u0026#39;C\u0026#39;: c}, index=index) df = df.rename_axis(\u0026#39;ID\u0026#39;) - arr = df.values + arr = df.to_numpy() Source: Paper Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/13187778/convert-pandas-dataframe-to-numpy-array/54508052#54508052  Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/dataframe-coversion-api-misused/","summary":"Description When converting DataFrame to NumPy array, it is better to use df.to\\_numpy() than df.values(). As noted in a post, df.values() has inconsistency problem. With .values it is unclear whether the returned value would be the actual array, some transformation of it, or one of the Pandas custom arrays. However, .values is not deprecated yet. Although the library developers note it as a warning in the documentation, it does not log a warning or error when compiling if we use .","title":"Dataframe Coversion API Misused"},{"content":"Description A post provides a better coding solution for the regular expression, which might be able to apply to the Nature Language Processing (NLP) preprocessing process. NLP tasks are data-intensive and often take a long time to clean the data, so it would be good to save some time when preprocessing the data. The post noted that regex.sub() and str.translate() work faster than str.replace() in practice in Pandas library. The more efficient solution is worth considering.\nType API Specific\nExisting Stage Data Preparation\nEffect Efficiency\nExample ### Pandas import Pandas as pd df = pd.DataFrame({\u0026#39;text\u0026#39;:[\u0026#39;a..b?!??\u0026#39;, \u0026#39;%hgh\u0026amp;12\u0026#39;,\u0026#39;abc123!!!\u0026#39;, \u0026#39;$$$1234\u0026#39;]}) # Violated Code df[\u0026#39;text\u0026#39;] = df[\u0026#39;text\u0026#39;].str.replace(r\u0026#39;[^\\w\\s]+\u0026#39;, \u0026#39;\u0026#39;) # Recommended Fix punct = \u0026#39;!\u0026#34;#$%\u0026amp;\\\u0026#39;()*+,-./:;\u0026lt;=\u0026gt;?@[\\\\]^_`{}~\u0026#39; # `|` is not present here transtab = str.maketrans(dict.fromkeys(punct, \u0026#39;\u0026#39;)) df[\u0026#39;text\u0026#39;] = \u0026#39;|\u0026#39;.join(df[\u0026#39;text\u0026#39;].tolist()).translate(transtab).split(\u0026#39;|\u0026#39;) Source: Paper Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/50444346/fast-punctuation-removal-with-pandas/50444347#50444347  Documentation ","permalink":"https://hynn01.github.io/dslinter/deprecated/regular-expression-solution-not-optimal/","summary":"Description A post provides a better coding solution for the regular expression, which might be able to apply to the Nature Language Processing (NLP) preprocessing process. NLP tasks are data-intensive and often take a long time to clean the data, so it would be good to save some time when preprocessing the data. The post noted that regex.sub() and str.translate() work faster than str.replace() in practice in Pandas library. The more efficient solution is worth considering.","title":"Regular Expression Solution Not Optimal"},{"content":"Description Several bugs can be caused by tensor unaligned. Usually, the unaligned tensor problems cannot be identified at the code level, but we can explicitly control one. It is recommended to explicitly set the shape of the input for tf.Variable() to make the tensor aligned. In this way, we can alleviate the unaligned tensor problem.\nType API Specific\nExisting Stage Data Preparation\nEffect Error-prone\nExample ### TensorFlow import Tensorflow as tf # Violated Code normal_dist = tf.truncated_normal() w = tf.Variable(nonrmal_dist, name = \u0026#39;weights\u0026#39;) # Recommended Fix normal_dist = tf.truncated_normal() normal_dist.set_shape(32,32) w = tf.Variable(nonrmal_dist, name = \u0026#39;weights\u0026#39;) Source: Paper  Yuhao Zhang, Yifan Chen, Shing-Chi Cheung, Yingfei Xiong, and Lu Zhang. 2018.An empirical study on TensorFlow program bugs. InProceedings of the 27th ACMSIGSOFT International Symposium on Software Testing and Analysis. 129–140. Md Johirul Islam, Giang Nguyen, Rangeet Pan, and Hridesh Rajan. 2019. Acomprehensive study on deep learning bug characteristics. InProceedings of the2019 27th ACM Joint Meeting on European Software Engineering Conference andSymposium on the Foundations of Software Engineering. 510–520.  Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/34079787/tensor-with-unspecified-dimension-in-tensorflow  Documentation ","permalink":"https://hynn01.github.io/dslinter/deprecated/tensor-shape-unset/","summary":"Description Several bugs can be caused by tensor unaligned. Usually, the unaligned tensor problems cannot be identified at the code level, but we can explicitly control one. It is recommended to explicitly set the shape of the input for tf.Variable() to make the tensor aligned. In this way, we can alleviate the unaligned tensor problem.\nType API Specific\nExisting Stage Data Preparation\nEffect Error-prone\nExample ### TensorFlow import Tensorflow as tf # Violated Code normal_dist = tf.","title":"Tensor Shape Unset"},{"content":"Description When using pd.eval() in Pandas library, the numexpr is optimized for performance and python options offer no performance benefit over numexpr. Generally, it is not recommended to set the parameter to python. The developers should be careful when explicitly set this parameter.\nType API Specific\nExisting Stage Data Preparation\nEffect Efficiency\nExample ### Pandas import pandas as pd # Violated Code pd.eval(\u0026#39;df.A.str.contains(\u0026#34;ab\u0026#34;)\u0026#39;, engine=\u0026#39;python\u0026#39;) # Recommended Fix pd.eval(\u0026#39;df.A.str.contains(\u0026#34;ab\u0026#34;)\u0026#39;) Source: Paper Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/53779986/dynamically-evaluate-an-expression-from-a-formula-in-pandas/53779987#53779987  Documentation ","permalink":"https://hynn01.github.io/dslinter/deprecated/backend-engine-mischoosed/","summary":"Description When using pd.eval() in Pandas library, the numexpr is optimized for performance and python options offer no performance benefit over numexpr. Generally, it is not recommended to set the parameter to python. The developers should be careful when explicitly set this parameter.\nType API Specific\nExisting Stage Data Preparation\nEffect Efficiency\nExample ### Pandas import pandas as pd # Violated Code pd.eval(\u0026#39;df.A.str.contains(\u0026#34;ab\u0026#34;)\u0026#39;, engine=\u0026#39;python\u0026#39;) # Recommended Fix pd.eval(\u0026#39;df.A.str.contains(\u0026#34;ab\u0026#34;)\u0026#39;) Source: Paper Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.","title":"Backend Engine Mischoosed"},{"content":"Description Some new developers are not aware of using the existing function and writing the function by themselves. However, it is recommended to use the APIs because the APIs provided by the library often consider more things. For instance, in a post, the developer does not use the DataLoader and feeds the data directly to the network. The answerer noted that using DataLoader has several benefits: 1) It allows the developers to sample the data randomly. 2) It does not preload data into memory, which is particularly useful for huge datasets. 3) It operates in the background of code, so it fetches data parallel to train thus saving time. 4) It is very efficient at batching the data. Therefore, it is better to use the DataLoader API than manually splitting the data and directly feeding the data into the network.\nType API Specific\nExisting Stage Data Segregation\nEffect Robustness\nExample ### PyTorch # 1. Load and normalize CIFAR10 import torch import torchvision import torchvision.transforms as transforms import torch.utils.data as data_utils transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) batch_size = 4 trainset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=True, download=True, transform=transform) + trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, + shuffle=True, num_workers=0)  testset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=False, download=True, transform=transform) + testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, + shuffle=False, num_workers=0)  classes = (\u0026#39;plane\u0026#39;, \u0026#39;car\u0026#39;, \u0026#39;bird\u0026#39;, \u0026#39;cat\u0026#39;, \u0026#39;deer\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;frog\u0026#39;, \u0026#39;horse\u0026#39;, \u0026#39;ship\u0026#39;, \u0026#39;truck\u0026#39;) # 2. Define a Convolutional Neural Network import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = torch.flatten(x, 1) # flatten all dimensions except batch x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() # 3. Define a Loss function and optimizer import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 4. Train the network for epoch in range(2): # loop over the dataset multiple times running_loss = 0.0 net.train() - for i in range(int(len(trainset) / batch_size)): + for i, data in enumerate(trainloader, 0):  # get the inputs; data is a list of [inputs, labels] - inputs, labels = (trainset.data[i * batch_size: (i + 1) * batch_size] - , trainset.targets[i * batch_size: (i + 1) * batch_size]) + inputs, labels = data  # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print(f\u0026#39;[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\u0026#39;) running_loss = 0.0 # validation net.eval() #... print(\u0026#39;Finished Training\u0026#39;) PATH = \u0026#39;./cifar_net.pth\u0026#39; torch.save(net.state_dict(), PATH) # 5. Test the network on the test data correct = 0 total = 0 # since we\u0026#39;re not training, we don\u0026#39;t need to calculate the gradients for our outputs with torch.no_grad(): for data in testloader: images, labels = data # calculate outputs by running images through the network outputs = net(images) # the class with the highest energy is what we choose as prediction _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(f\u0026#39;Accuracy of the network on the 10000 test images: {100 * correct // total} %\u0026#39;) Source: Paper Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/67066452/is-this-a-right-way-to-train-and-test-the-model-using-pytorch/67067242#67067242  Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/dataloader-unused/","summary":"Description Some new developers are not aware of using the existing function and writing the function by themselves. However, it is recommended to use the APIs because the APIs provided by the library often consider more things. For instance, in a post, the developer does not use the DataLoader and feeds the data directly to the network. The answerer noted that using DataLoader has several benefits: 1) It allows the developers to sample the data randomly.","title":"DataLoader Unused"},{"content":"Description np.matmul() in Numpy library is more readable than np.dot() in the semantic way. Whilenp.dot() provides heterogeneous behaviors depending on the shape of the data, np.matmul() behaves in a consistent way. When the multiply operation is performed on two-dimension matrixes, two APIs give a same result. However, np.matmul() is preferred than np.dot() for its clear semantic.\nType API Specific\nExisting Stage Model Training\nEffect Readability\nExample ### NumPy import numpy as np a = [[1, 0], [0, 1]] b = [[4, 1], [2, 2]] - np.dot(a, b) + np.matmul(a, b) Source: Paper Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/54160155/does-np-dot-automatically-transpose-vectors/54161169#54161169  Documentation  https://numpy.org/doc/stable/reference/generated/numpy.dot.html#numpy.dot  ","permalink":"https://hynn01.github.io/dslinter/code-smells/matrix-multiplication-api-misused/","summary":"Description np.matmul() in Numpy library is more readable than np.dot() in the semantic way. Whilenp.dot() provides heterogeneous behaviors depending on the shape of the data, np.matmul() behaves in a consistent way. When the multiply operation is performed on two-dimension matrixes, two APIs give a same result. However, np.matmul() is preferred than np.dot() for its clear semantic.\nType API Specific\nExisting Stage Model Training\nEffect Readability\nExample ### NumPy import numpy as np a = [[1, 0], [0, 1]] b = [[4, 1], [2, 2]] - np.","title":"Matrix Multiplication API Misused"},{"content":"Description The AdamOptimizer class in the TensorFlow creates additional variables named \u0026ldquo;slots\u0026rdquo;. The variables must be initialized before training the model. Therefore, if the developer call initialize_all_variables() before calling AdamOptimizer and does not call the initializer afterward, the variables created by AdamOptimizer will not be initialized and might cause an error.\nType API Specific\nExisting Stage Model Training\nEffect Error-prone\nExample ### TensorFlow import tensorflow as tf # Violated Code init = tf.global_variables_initializer() train_op = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) sess = tf.Session() sess.run(init) # Recommended Fix train_op = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) init = tf.global_variables_initializer() sess = tf.Session() sess.run(init) Source: Paper  Yuhao Zhang, Yifan Chen, Shing-Chi Cheung, Yingfei Xiong, and Lu Zhang. 2018.An empirical study on TensorFlow program bugs. InProceedings of the 27th ACMSIGSOFT International Symposium on Software Testing and Analysis. 129–140.  Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/33788989/tensorflow-using-adam-optimizer  Documentation ","permalink":"https://hynn01.github.io/dslinter/deprecated/initialization-order-misused/","summary":"Description The AdamOptimizer class in the TensorFlow creates additional variables named \u0026ldquo;slots\u0026rdquo;. The variables must be initialized before training the model. Therefore, if the developer call initialize_all_variables() before calling AdamOptimizer and does not call the initializer afterward, the variables created by AdamOptimizer will not be initialized and might cause an error.\nType API Specific\nExisting Stage Model Training\nEffect Error-prone\nExample ### TensorFlow import tensorflow as tf # Violated Code init = tf.","title":"Initialization Order Misused"},{"content":"Description In PyTorch, self.nn() is different than self.nn.forward(). self.nn() also deals with all the register hooks, which would not be considered when calling the plain forward. Thus, it is recommended to use self.nn() than self.nn.forward().\nType API Specific\nExisting Stage Model Training\nEffect Robustness\nExample ### PyTorch # 1. Load and normalize CIFAR10 import torch import torchvision import torchvision.transforms as transforms transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) batch_size = 4 trainset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0) testset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0) classes = (\u0026#39;plane\u0026#39;, \u0026#39;car\u0026#39;, \u0026#39;bird\u0026#39;, \u0026#39;cat\u0026#39;, \u0026#39;deer\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;frog\u0026#39;, \u0026#39;horse\u0026#39;, \u0026#39;ship\u0026#39;, \u0026#39;truck\u0026#39;) # 2. Define a Convolutional Neural Network import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): - x = self.pool.forward(F.relu(self.conv1(x))) + x = self.pool(F.relu(self.conv1(x)))  x = self.pool(F.relu(self.conv2(x))) x = torch.flatten(x, 1) # flatten all dimensions except batch x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() # 3. Define a Loss function and optimizer import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 4. Train the network for epoch in range(2): # loop over the dataset multiple times running_loss = 0.0 for i, data in enumerate(trainloader, 0): # get the inputs; data is a list of [inputs, labels] inputs, labels = data # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print(f\u0026#39;[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\u0026#39;) running_loss = 0.0 print(\u0026#39;Finished Training\u0026#39;) PATH = \u0026#39;./cifar_net.pth\u0026#39; torch.save(net.state_dict(), PATH) # 5. Test the network on the test data correct = 0 total = 0 # since we\u0026#39;re not training, we don\u0026#39;t need to calculate the gradients for our outputs with torch.no_grad(): for data in testloader: images, labels = data # calculate outputs by running images through the network outputs = net(images) # the class with the highest energy is what we choose as prediction _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(f\u0026#39;Accuracy of the network on the 10000 test images: {100 * correct // total} %\u0026#39;) Source: Paper Grey Literature  https://github.com/IgorSusmelj/pytorch-styleguide  GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/pytorch-call-method-misused/","summary":"Description In PyTorch, self.nn() is different than self.nn.forward(). self.nn() also deals with all the register hooks, which would not be considered when calling the plain forward. Thus, it is recommended to use self.nn() than self.nn.forward().\nType API Specific\nExisting Stage Model Training\nEffect Robustness\nExample ### PyTorch # 1. Load and normalize CIFAR10 import torch import torchvision import torchvision.transforms as transforms transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.","title":"Pytorch Call Method Misused"},{"content":"Description In PyTorch, calling .eval() means we are going into the evaluation mode and the Dropout layer will be deactivated. If the training mode did not toggle back in time, the Dropout layer would not be used in some data training and thus affect the training result. Therefore, we suggest to \u0026ldquo;have the training mode set as close as possible to the inference step to avoid forgetting to set it\u0026rdquo;.\nType API Specific\nExisting Stage Model Training\nEffect Error-prone\nExample # PyTorch # 1. Load and normalize CIFAR10 import torch import torchvision import torchvision.transforms as transforms transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) batch_size = 4 trainset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0) testset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0) classes = (\u0026#39;plane\u0026#39;, \u0026#39;car\u0026#39;, \u0026#39;bird\u0026#39;, \u0026#39;cat\u0026#39;, \u0026#39;deer\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;frog\u0026#39;, \u0026#39;horse\u0026#39;, \u0026#39;ship\u0026#39;, \u0026#39;truck\u0026#39;) # 2. Define a Convolutional Neural Network import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = torch.flatten(x, 1) # flatten all dimensions except batch x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() # 3. Define a Loss function and optimizer import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 4. Train the network for epoch in range(2): # loop over the dataset multiple times running_loss = 0.0 - net.train()  for i, data in enumerate(trainloader, 0): # get the inputs; data is a list of [inputs, labels] + net.train()  inputs, labels = data # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print(f\u0026#39;[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\u0026#39;) running_loss = 0.0 # validation net.eval() #... print(\u0026#39;Finished Training\u0026#39;) PATH = \u0026#39;./cifar_net.pth\u0026#39; torch.save(net.state_dict(), PATH) # 5. Test the network on the test data correct = 0 total = 0 # since we\u0026#39;re not training, we don\u0026#39;t need to calculate the gradients for our outputs with torch.no_grad(): for data in testloader: images, labels = data # calculate outputs by running images through the network outputs = net(images) # the class with the highest energy is what we choose as prediction _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(f\u0026#39;Accuracy of the network on the 10000 test images: {100 * correct // total} %\u0026#39;) Source: Paper Grey Literature  https://medium.com/missinglink-deep-learning-platform/most-common-neural-net-pytorch-mistakes-456560ada037  GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/train-eval-mode-improper-toggling/","summary":"Description In PyTorch, calling .eval() means we are going into the evaluation mode and the Dropout layer will be deactivated. If the training mode did not toggle back in time, the Dropout layer would not be used in some data training and thus affect the training result. Therefore, we suggest to \u0026ldquo;have the training mode set as close as possible to the inference step to avoid forgetting to set it\u0026rdquo;.","title":"Train Eval Mode Improper Toggling"},{"content":"Description Developers should use optimizer.zero_grad(), loss_fn.backward(), optimizer.step() together and should be forget to use optimizer.zero_grad() before loss_fn.backward(). optimizer.zero_grad() clears the old gradients from last step. If this API is not used, the gradients will be accumulated from all loss.backward() calls and it will lead to the gradient explosion, which fails the training.\nType API Specific\nExisting Stage Model Training\nEffect Error-prone\nExample # PyTorch # 1. Load and normalize CIFAR10 import torch import torchvision import torchvision.transforms as transforms transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) batch_size = 4 trainset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0) testset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0) classes = (\u0026#39;plane\u0026#39;, \u0026#39;car\u0026#39;, \u0026#39;bird\u0026#39;, \u0026#39;cat\u0026#39;, \u0026#39;deer\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;frog\u0026#39;, \u0026#39;horse\u0026#39;, \u0026#39;ship\u0026#39;, \u0026#39;truck\u0026#39;) # 2. Define a Convolutional Neural Network import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = torch.flatten(x, 1) # flatten all dimensions except batch x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() # 3. Define a Loss function and optimizer import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 4. Train the network for epoch in range(2): # loop over the dataset multiple times running_loss = 0.0 for i, data in enumerate(trainloader, 0): # get the inputs; data is a list of [inputs, labels] inputs, labels = data + # zero the parameter gradients + optimizer.zero_grad()  # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print(f\u0026#39;[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\u0026#39;) running_loss = 0.0 print(\u0026#39;Finished Training\u0026#39;) PATH = \u0026#39;./cifar_net.pth\u0026#39; torch.save(net.state_dict(), PATH) # 5. Test the network on the test data correct = 0 total = 0 # since we\u0026#39;re not training, we don\u0026#39;t need to calculate the gradients for our outputs with torch.no_grad(): for data in testloader: images, labels = data # calculate outputs by running images through the network outputs = net(images) # the class with the highest energy is what we choose as prediction _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(f\u0026#39;Accuracy of the network on the 10000 test images: {100 * correct // total} %\u0026#39;) Source: Paper Grey Literature  https://medium.com/missinglink-deep-learning-platform/most-common-neural-net-pytorch-mistakes-456560ada037  GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/zero_grad-not-used-before-backward/","summary":"Description Developers should use optimizer.zero_grad(), loss_fn.backward(), optimizer.step() together and should be forget to use optimizer.zero_grad() before loss_fn.backward(). optimizer.zero_grad() clears the old gradients from last step. If this API is not used, the gradients will be accumulated from all loss.backward() calls and it will lead to the gradient explosion, which fails the training.\nType API Specific\nExisting Stage Model Training\nEffect Error-prone\nExample # PyTorch # 1. Load and normalize CIFAR10 import torch import torchvision import torchvision.","title":"Zero_grad Not Used Before Backward"},{"content":"Description Different loss APIs take different input formats, but the difference is not clarified in some documentations, so it is easy to misuse. For example, in PyTorch, the NLLLoss takes the output of LogSoftmax as the input. If the input given to NLLLoss has not been processed by LogSoftmax, it might lead to a wrong result.\nType API Specific\nExisting Stage Model Training\nEffect Error-prone\nExample ### PyTorch import torch.nn as nn import torch + m = nn.LogSoftmax(dim=1) loss = nn.NLLLoss() input = torch.randn(3, 5, requires_grad=True) target = torch.tensor([1, 0, 4]) - output = loss(input, target) + output = loss(m(input), target) output.backward() Source: Paper Grey Literature  https://medium.com/missinglink-deep-learning-platform/most-common-neural-net-pytorch-mistakes-456560ada037  GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/loss-api-misused/","summary":"Description Different loss APIs take different input formats, but the difference is not clarified in some documentations, so it is easy to misuse. For example, in PyTorch, the NLLLoss takes the output of LogSoftmax as the input. If the input given to NLLLoss has not been processed by LogSoftmax, it might lead to a wrong result.\nType API Specific\nExisting Stage Model Training\nEffect Error-prone\nExample ### PyTorch import torch.nn as nn import torch + m = nn.","title":"Loss API Misused"},{"content":"Description In neural network, if all the weights are initialized to a constant, i.e., all the neurons starts with the same weight, all the neurons will follow the same gradient during the backward propagation update. As a result, neurons will learn same features in each iterations. In this way, the nueral netwok will provide a poor result.\nType Generic\nExisting Stage Model Training\nEffect Error-prone\nExample # https://github.com/aladdinpersson/Machine-Learning-Collection/blob/a2ee9271b5280be6994660c7982d0f44c67c3b63/ML/Projects/Exploring_MNIST/networks/lenet.py import torch import torch.nn as nn import torch.nn.functional as F class LeNet(nn.Module): def __init__(self, in_channels, init_weights=True, num_classes=10): super(LeNet, self).__init__() self.num_classes = num_classes if init_weights: self._initialize_weights() self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5) self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): z1 = self.conv1(x) # 6 x 28 x 28 a1 = F.relu(z1) # 6 x 28 x 28 a1 = F.max_pool2d(a1, kernel_size=2, stride=2) # 6 x 14 x 14 z2 = self.conv2(a1) # 16 x 10 x 10 a2 = F.relu(z2) # 16 x 10 x 10 a2 = F.max_pool2d(a2, kernel_size=2, stride=2) # 16 x 5 x 5 flatten_a2 = a2.view(a2.size(0), -1) z3 = self.fc1(flatten_a2) a3 = F.relu(z3) z4 = self.fc2(a3) a4 = F.relu(z4) z5 = self.fc3(a4) return z5 def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=\u0026#34;fan_out\u0026#34;, nonlinearity=\u0026#34;relu\u0026#34;) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.BatchNorm2d): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) def test_lenet(): net = LeNet(1) x = torch.randn(64, 1, 32, 32) y = net(x) print(y.size()) test_lenet() Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/deprecated/initialize-weight-to-zero/","summary":"Description In neural network, if all the weights are initialized to a constant, i.e., all the neurons starts with the same weight, all the neurons will follow the same gradient during the backward propagation update. As a result, neurons will learn same features in each iterations. In this way, the nueral netwok will provide a poor result.\nType Generic\nExisting Stage Model Training\nEffect Error-prone\nExample # https://github.com/aladdinpersson/Machine-Learning-Collection/blob/a2ee9271b5280be6994660c7982d0f44c67c3b63/ML/Projects/Exploring_MNIST/networks/lenet.py import torch import torch.","title":"Initialize Weight to a Constant"},{"content":"Description In deep learning, regularization can help control overfitting, speed up the training process by dealing with noise and outliers. Developers should check whether they are able to make use of regularization to improve performance.\nType Generic\nExisting Stage Model Training\nEffect Efficiency\nExample ### TensorFlow # Violated Code layer = tf.keras.layers.Dense( 5, input_dim=5, kernel_initializer=\u0026#39;ones\u0026#39;, kernel_regularizer=tf.keras.regularizers.L1(0.01), activity_regularizer=tf.keras.regularizers.L2(0.01)) # Recommended Fix layer = tf.keras.layers.Dense( 5, input_dim=5, kernel_initializer=\u0026#39;ones\u0026#39;) ### PyTorch # Violated Code optimizer = torch.optim.Adam(model.parameters(), lr=1e-4) # Recommended Fix optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5) Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/deprecated/missing-regularization/","summary":"Description In deep learning, regularization can help control overfitting, speed up the training process by dealing with noise and outliers. Developers should check whether they are able to make use of regularization to improve performance.\nType Generic\nExisting Stage Model Training\nEffect Efficiency\nExample ### TensorFlow # Violated Code layer = tf.keras.layers.Dense( 5, input_dim=5, kernel_initializer=\u0026#39;ones\u0026#39;, kernel_regularizer=tf.keras.regularizers.L1(0.01), activity_regularizer=tf.keras.regularizers.L2(0.01)) # Recommended Fix layer = tf.keras.layers.Dense( 5, input_dim=5, kernel_initializer=\u0026#39;ones\u0026#39;) ### PyTorch # Violated Code optimizer = torch.","title":"Missing Regularization"},{"content":"Description The performance of the machine learning model can be measured by different metrics, including threshold-dependent metrics(e.g., F-measure) or threshold-independent metrics(e.g., Area Under the receiver operating characteristic curve (AUC)). Choosing a specific threshold is tricky and can lead to a less-interpretable result. Therefore, threshold-independent is more robust and should be preferred over threshold-independent metrics.\nType Generic\nExisting Stage Model Evaluation\nEffect Robustness\nExample ### Scikit-Learn from sklearn import metrics y_true = [0, 1, 2, 0, 1, 2] y_pred = [0, 2, 1, 0, 0, 1] metrics.f1_score(y_true, y_pred, average=\u0026#39;weighted\u0026#39;) + y = [1, 1, 2, 2] + pred = [0.1, 0.4, 0.35, 0.8] + fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2) + print(metrics.auc(fpr, tpr)) Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/threshold-dependent-validation/","summary":"Description The performance of the machine learning model can be measured by different metrics, including threshold-dependent metrics(e.g., F-measure) or threshold-independent metrics(e.g., Area Under the receiver operating characteristic curve (AUC)). Choosing a specific threshold is tricky and can lead to a less-interpretable result. Therefore, threshold-independent is more robust and should be preferred over threshold-independent metrics.\nType Generic\nExisting Stage Model Evaluation\nEffect Robustness\nExample ### Scikit-Learn from sklearn import metrics y_true = [0, 1, 2, 0, 1, 2] y_pred = [0, 2, 1, 0, 0, 1] metrics.","title":"Threshold Dependent Validation"},{"content":"Description Context Problem Solution Type Existing Stage Effect Example ### TensorFlow example 1 import tensorflow as tf a = tf.constant([[1., 2.], [3., 4.]]) b = tf.constant([[1.], [2.]]) - c = a + tf.tile(b, [1, 2]) + c = a + b  ### TensorFlow example 2 import tensorflow as tf a = tf.random.uniform([5, 3, 5]) b = tf.random.uniform([5, 1, 6]) - tiled_b = tf.tile(b, [1, 3, 1]) - c = tf.concat([a, tiled_b], 2) - d = tf.keras.layers.Dense(10, activation=tf.nn.relu).apply(c) + pa = tf.keras.layers.Dense(10).apply(a) + pb = tf.keras.layers.Dense(10).apply(b) + d = tf.nn.relu(pa + pb) Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/broadcasting-feature-not-used/","summary":"Description Context Problem Solution Type Existing Stage Effect Example ### TensorFlow example 1 import tensorflow as tf a = tf.constant([[1., 2.], [3., 4.]]) b = tf.constant([[1.], [2.]]) - c = a + tf.tile(b, [1, 2]) + c = a + b  ### TensorFlow example 2 import tensorflow as tf a = tf.random.uniform([5, 3, 5]) b = tf.random.uniform([5, 1, 6]) - tiled_b = tf.tile(b, [1, 3, 1]) - c = tf.","title":"Broadcasting Feature Not Used"},{"content":"Description Context Problem Solution Type Existing Stage Effect Example import pandas as pd df = pd.read_csv(\u0026#39;data.csv\u0026#39;) + df = df[[\u0026#39;col1\u0026#39;, \u0026#39;col2\u0026#39;, \u0026#39;col3\u0026#39;]] Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/columns-and-datatype-not-explicitly-set/","summary":"Description Context Problem Solution Type Existing Stage Effect Example import pandas as pd df = pd.read_csv(\u0026#39;data.csv\u0026#39;) + df = df[[\u0026#39;col1\u0026#39;, \u0026#39;col2\u0026#39;, \u0026#39;col3\u0026#39;]] Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation ","title":"Columns and DataType Not Explicitly Set"},{"content":"Description Context Problem Solution Type Existing Stage Effect Example import pandas as pd + import numpy as np  df = pd.DataFrame([]) - df[\u0026#39;new_col_int\u0026#39;] = 0 - df[\u0026#39;new_col_str\u0026#39;] = \u0026#39;\u0026#39; + df[\u0026#39;new_col_float\u0026#39;] = np.nan + df[\u0026#39;new_col_int\u0026#39;] = pd.Series(dtype=\u0026#39;int\u0026#39;) + df[\u0026#39;new_col_str\u0026#39;] = pd.Series(dtype=\u0026#39;object\u0026#39;) Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/empty-column-misinitialization/","summary":"Description Context Problem Solution Type Existing Stage Effect Example import pandas as pd + import numpy as np  df = pd.DataFrame([]) - df[\u0026#39;new_col_int\u0026#39;] = 0 - df[\u0026#39;new_col_str\u0026#39;] = \u0026#39;\u0026#39; + df[\u0026#39;new_col_float\u0026#39;] = np.nan + df[\u0026#39;new_col_int\u0026#39;] = pd.Series(dtype=\u0026#39;int\u0026#39;) + df[\u0026#39;new_col_str\u0026#39;] = pd.Series(dtype=\u0026#39;object\u0026#39;) Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation ","title":"Empty Column Misinitialization"},{"content":"Description Context Problem Solution Type Existing Stage Effect Example import pandas as pd df1 = pd.DataFrame({\u0026#39;key\u0026#39;: [\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;, \u0026#39;foo\u0026#39;], \u0026#39;value\u0026#39;: [1, 2, 3, 5]}) df2 = pd.DataFrame({\u0026#39;key\u0026#39;: [\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;, \u0026#39;foo\u0026#39;], \u0026#39;value\u0026#39;: [5, 6, 7, 8]}) - df3 = df1.merge(df2) + df3 = df1.merge( + df2, + how=\u0026#39;inner\u0026#39;, + on=\u0026#39;key\u0026#39;, + validate=\u0026#39;m:m\u0026#39; + ) Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/merge-api-parameter-not-explicitly-set/","summary":"","title":"Merge API Parameter Not Explicitly Set"},{"content":"Description Context Problem Solution Type Existing Stage Effect Example ### TensorFlow import tensorflow as tf @tf.function def fibonacci(n): a = tf.constant(1) b = tf.constant(1) - c = tf.constant([1, 1]) + c = tf.TensorArray(tf.int32, n) + c = c.write(0, a) + c = c.write(1, b)  for i in range(2, n): a, b = b, a + b - c = tf.concat([c, [b]], 0) +\tc = c.write(i, b)  - return c +\treturn c.stack()  n = tf.constant(5) d = fibonacci(n) Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation ","permalink":"https://hynn01.github.io/dslinter/code-smells/tensorarray-not-used/","summary":"Description Context Problem Solution Type Existing Stage Effect Example ### TensorFlow import tensorflow as tf @tf.function def fibonacci(n): a = tf.constant(1) b = tf.constant(1) - c = tf.constant([1, 1]) + c = tf.TensorArray(tf.int32, n) + c = c.write(0, a) + c = c.write(1, b)  for i in range(2, n): a, b = b, a + b - c = tf.concat([c, [b]], 0) +\tc = c.write(i, b)  - return c +\treturn c.","title":"TensorArray Not Used"}]