<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Data Leakage | DSLinter - Linter for Machine Learning - Specific Code Smells</title>
<meta name=keywords content="generic,data preparation,error-prone">
<meta name=description content="Description &ldquo;Data Leakage happens when the data you are using to train a machine learning algorithm happens to have the information you are trying to predict.&rdquo; It results in overly optimistic performance during testing and poor performance in real-world usage. There are two main sources of data leakage: leaky predictors and a leaky validation strategy. Leaky predictors refer to the situation where some features updated or created after the target value is realized are included.">
<meta name=author content>
<link rel=canonical href=/code-smells/data-leakage/>
<meta name=google-site-verification content="XYZabc">
<meta name=yandex-verification content="XYZabc">
<meta name=msvalidate.01 content="XYZabc">
<link crossorigin=anonymous href=/assets/css/stylesheet.min.548091f41dc92b4a213f8dc4a49e22545a96b7d1b4ae4ad73c2ab3a70e4e8ea1.css integrity="sha256-VICR9B3JK0ohP43EpJ4iVFqWt9G0rkrXPCqzpw5OjqE=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=16x16 href=%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=32x32 href=%3Clink%20/%20abs%20url%3E>
<link rel=apple-touch-icon href=%3Clink%20/%20abs%20url%3E>
<link rel=mask-icon href=%3Clink%20/%20abs%20url%3E>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.91.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
</noscript><meta property="og:title" content="Data Leakage">
<meta property="og:description" content="Description &ldquo;Data Leakage happens when the data you are using to train a machine learning algorithm happens to have the information you are trying to predict.&rdquo; It results in overly optimistic performance during testing and poor performance in real-world usage. There are two main sources of data leakage: leaky predictors and a leaky validation strategy. Leaky predictors refer to the situation where some features updated or created after the target value is realized are included.">
<meta property="og:type" content="article">
<meta property="og:url" content="/code-smells/data-leakage/"><meta property="article:section" content="Code Smells">
<meta property="og:site_name" content="DSLinter - Linter for Machine Learning Application - Specific Code Smells">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Data Leakage">
<meta name=twitter:description content="Description &ldquo;Data Leakage happens when the data you are using to train a machine learning algorithm happens to have the information you are trying to predict.&rdquo; It results in overly optimistic performance during testing and poor performance in real-world usage. There are two main sources of data leakage: leaky predictors and a leaky validation strategy. Leaky predictors refer to the situation where some features updated or created after the target value is realized are included.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":3,"name":"Data Leakage","item":"/code-smells/data-leakage/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Data Leakage","name":"Data Leakage","description":"Description \u0026ldquo;Data Leakage happens when the data you are using to train a machine learning algorithm happens to have the information you are trying to predict.\u0026rdquo; It results in overly optimistic performance during testing and poor performance in real-world usage. There are two main sources of data leakage: leaky predictors and a leaky validation strategy. Leaky predictors refer to the situation where some features updated or created after the target value is realized are included.","keywords":["generic","data preparation","error-prone"],"articleBody":"Description “Data Leakage happens when the data you are using to train a machine learning algorithm happens to have the information you are trying to predict.” It results in overly optimistic performance during testing and poor performance in real-world usage. There are two main sources of data leakage: leaky predictors and a leaky validation strategy. Leaky predictors refer to the situation where some features updated or created after the target value is realized are included. This kind of data leakage can only be inspected at the data level rather than the code level. Leaky validation strategy refers to the scene where information from training data is getting mixed with validation data. This kind of pitfall can be avoided by checking the code carefully. One best practice in Scikit-Learn is to use Pipeline API to prevent data leakage.\nType Generic\nExisting Stage Data Preparation\nEffect Error-prone\nExample ### Scikit-Learn from sklearn.model_selection import train_test_split from sklearn.feature_selection import SelectKBest from sklearn.ensemble import GradientBoostingClassifier from sklearn.metrics import accuracy_score import numpy as np + from sklearn.pipeline import make_pipeline  n_samples, n_features, n_classes = 200, 10000, 2 rng = np.random.RandomState(42) X = rng.standard_normal((n_samples, n_features)) y = rng.choice(n_classes, n_samples) - X_selected = SelectKBest(k=25).fit_transform(X, y) - X_train, X_test, y_train, y_test = train_test_split(X_selected, y, random_state=42) - gbc = GradientBoostingClassifier(random_state=1) - gbc.fit(X_train, y_train) - y_pred = gbc.predict(X_test) + X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) + pipeline = make_pipeline(SelectKBest(k=25), GradientBoostingClassifier(random_state=1)) + pipeline.fit(X_train, y_train) + y_pred = pipeline.predict(X_test)  accuracy_score(y_test, y_pred) Source: Paper  MPA Haakman. 2020. Studying the Machine Learning Lifecycle and Improving Code Quality of Machine Learning Applications. (2020).  Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/43816718/keras-regression-using-scikit-learn-standardscaler-with-pipeline-and-without-pip/43816833#43816833  Documentation  https://scikit-learn.org/stable/common_pitfalls.html  ","wordCount":"267","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"/code-smells/data-leakage/"},"publisher":{"@type":"Organization","name":"DSLinter - Linter for Machine Learning - Specific Code Smells","logo":{"@type":"ImageObject","url":"%3Clink%20/%20abs%20url%3E"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href accesskey=h title="DSLinter - Linter for Machine Learning - Specific Code Smells (Alt + H)">DSLinter - Linter for Machine Learning - Specific Code Smells</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=/code-smells/ title="Code Smells">
<span>Code Smells</span>
</a>
</li>
<li>
<a href=search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
<li>
<a href title=Survey>
<span>Survey</span>
</a>
</li>
<li>
<a href=/tags/ title=Tags>
<span>Tags</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href>Home</a></div>
<h1 class=post-title>
Data Leakage
</h1>
<div class=post-meta>
</div>
</header>
<div class=post-content><h3 id=description>Description<a hidden class=anchor aria-hidden=true href=#description>#</a></h3>
<p>&ldquo;Data Leakage happens when the data you are using to train a machine learning algorithm happens to have the information you are trying to predict.&rdquo; It results in overly optimistic performance during testing and poor performance in real-world usage. There are two main sources of data leakage: leaky predictors and a leaky validation strategy. Leaky predictors refer to the situation where some features updated or created after the target value is realized are included. This kind of data leakage can only be inspected at the data level rather than the code level. Leaky validation strategy refers to the scene where information from training data is getting mixed with validation data. This kind of pitfall can be avoided by checking the code carefully. One best practice in Scikit-Learn is to use Pipeline API to prevent data leakage.</p>
<h3 id=type>Type<a hidden class=anchor aria-hidden=true href=#type>#</a></h3>
<p>Generic</p>
<h3 id=existing-stage>Existing Stage<a hidden class=anchor aria-hidden=true href=#existing-stage>#</a></h3>
<p>Data Preparation</p>
<h3 id=effect>Effect<a hidden class=anchor aria-hidden=true href=#effect>#</a></h3>
<p>Error-prone</p>
<h3 id=example>Example<a hidden class=anchor aria-hidden=true href=#example>#</a></h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff>### Scikit-Learn
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score
import numpy as np
<span style=color:#a6e22e>+ from sklearn.pipeline import make_pipeline
</span><span style=color:#a6e22e></span>
n_samples, n_features, n_classes = 200, 10000, 2
rng = np.random.RandomState(42)
X = rng.standard_normal((n_samples, n_features))
y = rng.choice(n_classes, n_samples)

<span style=color:#f92672>- X_selected = SelectKBest(k=25).fit_transform(X, y)
</span><span style=color:#f92672>- X_train, X_test, y_train, y_test = train_test_split(X_selected, y, random_state=42)
</span><span style=color:#f92672>- gbc = GradientBoostingClassifier(random_state=1)
</span><span style=color:#f92672>- gbc.fit(X_train, y_train)
</span><span style=color:#f92672>- y_pred = gbc.predict(X_test)
</span><span style=color:#f92672></span><span style=color:#a6e22e>+ X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
</span><span style=color:#a6e22e>+ pipeline = make_pipeline(SelectKBest(k=25), GradientBoostingClassifier(random_state=1))
</span><span style=color:#a6e22e>+ pipeline.fit(X_train, y_train)
</span><span style=color:#a6e22e>+ y_pred = pipeline.predict(X_test)
</span><span style=color:#a6e22e></span>
accuracy_score(y_test, y_pred)
</code></pre></div><h3 id=source>Source:<a hidden class=anchor aria-hidden=true href=#source>#</a></h3>
<h4 id=paper>Paper<a hidden class=anchor aria-hidden=true href=#paper>#</a></h4>
<ul>
<li>MPA Haakman. 2020. Studying the Machine Learning Lifecycle and Improving Code Quality of Machine Learning Applications. (2020).</li>
</ul>
<h4 id=grey-literature>Grey Literature<a hidden class=anchor aria-hidden=true href=#grey-literature>#</a></h4>
<h4 id=github-commit>GitHub Commit<a hidden class=anchor aria-hidden=true href=#github-commit>#</a></h4>
<h4 id=stack-overflow>Stack Overflow<a hidden class=anchor aria-hidden=true href=#stack-overflow>#</a></h4>
<ul>
<li><a href=https://stackoverflow.com/questions/43816718/keras-regression-using-scikit-learn-standardscaler-with-pipeline-and-without-pip/43816833#43816833>https://stackoverflow.com/questions/43816718/keras-regression-using-scikit-learn-standardscaler-with-pipeline-and-without-pip/43816833#43816833</a></li>
</ul>
<h4 id=documentation>Documentation<a hidden class=anchor aria-hidden=true href=#documentation>#</a></h4>
<ul>
<li><a href=https://scikit-learn.org/stable/common_pitfalls.html>https://scikit-learn.org/stable/common_pitfalls.html</a></li>
</ul>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=/tags/generic/>generic</a></li>
<li><a href=/tags/data-preparation/>data preparation</a></li>
<li><a href=/tags/error-prone/>error-prone</a></li>
</ul>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href>DSLinter - Linter for Machine Learning - Specific Code Smells</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>