<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Initialize Weight to a Constant | DSLinter - Linter for Machine Learning - Specific Code Smells</title>
<meta name=keywords content="added,generic,model training,error-prone">
<meta name=description content="Description In neural network, if all the weights are initialized to a constant, i.e., all the neurons starts with the same weight, all the neurons will follow the same gradient during the backward propagation update. As a result, neurons will learn same features in each iterations. In this way, the nueral netwok will provide a poor result.
Type Generic
Existing Stage Model Training
Effect Error-prone
Example # https://github.com/aladdinpersson/Machine-Learning-Collection/blob/a2ee9271b5280be6994660c7982d0f44c67c3b63/ML/Projects/Exploring_MNIST/networks/lenet.py import torch import torch.">
<meta name=author content>
<link rel=canonical href=/deprecated/initialize-weight-to-zero/>
<meta name=google-site-verification content="XYZabc">
<meta name=yandex-verification content="XYZabc">
<meta name=msvalidate.01 content="XYZabc">
<link crossorigin=anonymous href=/assets/css/stylesheet.min.548091f41dc92b4a213f8dc4a49e22545a96b7d1b4ae4ad73c2ab3a70e4e8ea1.css integrity="sha256-VICR9B3JK0ohP43EpJ4iVFqWt9G0rkrXPCqzpw5OjqE=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=16x16 href=%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=32x32 href=%3Clink%20/%20abs%20url%3E>
<link rel=apple-touch-icon href=%3Clink%20/%20abs%20url%3E>
<link rel=mask-icon href=%3Clink%20/%20abs%20url%3E>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.91.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
</noscript><meta property="og:title" content="Initialize Weight to a Constant">
<meta property="og:description" content="Description In neural network, if all the weights are initialized to a constant, i.e., all the neurons starts with the same weight, all the neurons will follow the same gradient during the backward propagation update. As a result, neurons will learn same features in each iterations. In this way, the nueral netwok will provide a poor result.
Type Generic
Existing Stage Model Training
Effect Error-prone
Example # https://github.com/aladdinpersson/Machine-Learning-Collection/blob/a2ee9271b5280be6994660c7982d0f44c67c3b63/ML/Projects/Exploring_MNIST/networks/lenet.py import torch import torch.">
<meta property="og:type" content="article">
<meta property="og:url" content="/deprecated/initialize-weight-to-zero/"><meta property="article:section" content="deprecated">
<meta property="og:site_name" content="DSLinter - Linter for Machine Learning Application - Specific Code Smells">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Initialize Weight to a Constant">
<meta name=twitter:description content="Description In neural network, if all the weights are initialized to a constant, i.e., all the neurons starts with the same weight, all the neurons will follow the same gradient during the backward propagation update. As a result, neurons will learn same features in each iterations. In this way, the nueral netwok will provide a poor result.
Type Generic
Existing Stage Model Training
Effect Error-prone
Example # https://github.com/aladdinpersson/Machine-Learning-Collection/blob/a2ee9271b5280be6994660c7982d0f44c67c3b63/ML/Projects/Exploring_MNIST/networks/lenet.py import torch import torch.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Deprecateds","item":"/deprecated/"},{"@type":"ListItem","position":3,"name":"Initialize Weight to a Constant","item":"/deprecated/initialize-weight-to-zero/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Initialize Weight to a Constant","name":"Initialize Weight to a Constant","description":"Description In neural network, if all the weights are initialized to a constant, i.e., all the neurons starts with the same weight, all the neurons will follow the same gradient during the backward propagation update. As a result, neurons will learn same features in each iterations. In this way, the nueral netwok will provide a poor result.\nType Generic\nExisting Stage Model Training\nEffect Error-prone\nExample # https://github.com/aladdinpersson/Machine-Learning-Collection/blob/a2ee9271b5280be6994660c7982d0f44c67c3b63/ML/Projects/Exploring_MNIST/networks/lenet.py import torch import torch.","keywords":["added","generic","model training","error-prone"],"articleBody":"Description In neural network, if all the weights are initialized to a constant, i.e., all the neurons starts with the same weight, all the neurons will follow the same gradient during the backward propagation update. As a result, neurons will learn same features in each iterations. In this way, the nueral netwok will provide a poor result.\nType Generic\nExisting Stage Model Training\nEffect Error-prone\nExample # https://github.com/aladdinpersson/Machine-Learning-Collection/blob/a2ee9271b5280be6994660c7982d0f44c67c3b63/ML/Projects/Exploring_MNIST/networks/lenet.py import torch import torch.nn as nn import torch.nn.functional as F class LeNet(nn.Module): def __init__(self, in_channels, init_weights=True, num_classes=10): super(LeNet, self).__init__() self.num_classes = num_classes if init_weights: self._initialize_weights() self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5) self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): z1 = self.conv1(x) # 6 x 28 x 28 a1 = F.relu(z1) # 6 x 28 x 28 a1 = F.max_pool2d(a1, kernel_size=2, stride=2) # 6 x 14 x 14 z2 = self.conv2(a1) # 16 x 10 x 10 a2 = F.relu(z2) # 16 x 10 x 10 a2 = F.max_pool2d(a2, kernel_size=2, stride=2) # 16 x 5 x 5 flatten_a2 = a2.view(a2.size(0), -1) z3 = self.fc1(flatten_a2) a3 = F.relu(z3) z4 = self.fc2(a3) a4 = F.relu(z4) z5 = self.fc3(a4) return z5 def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\") if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.BatchNorm2d): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) def test_lenet(): net = LeNet(1) x = torch.randn(64, 1, 32, 32) y = net(x) print(y.size()) test_lenet() Source: Paper Grey Literature GitHub Commit Stack Overflow Documentation ","wordCount":"260","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"/deprecated/initialize-weight-to-zero/"},"publisher":{"@type":"Organization","name":"DSLinter - Linter for Machine Learning - Specific Code Smells","logo":{"@type":"ImageObject","url":"%3Clink%20/%20abs%20url%3E"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href accesskey=h title="DSLinter - Linter for Machine Learning - Specific Code Smells (Alt + H)">DSLinter - Linter for Machine Learning - Specific Code Smells</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=/code-smells/ title="Code Smells">
<span>Code Smells</span>
</a>
</li>
<li>
<a href=search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
<li>
<a href title=Survey>
<span>Survey</span>
</a>
</li>
<li>
<a href=/tags/ title=Tags>
<span>Tags</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href>Home</a>&nbsp;Â»&nbsp;<a href=/deprecated/>Deprecateds</a></div>
<h1 class=post-title>
Initialize Weight to a Constant
</h1>
<div class=post-meta>
</div>
</header>
<div class=post-content><h3 id=description>Description<a hidden class=anchor aria-hidden=true href=#description>#</a></h3>
<p>In neural network, if all the weights are initialized to a constant, i.e., all the neurons starts with the same weight, all the neurons will follow the same gradient during the backward propagation update. As a result, neurons will learn same features in each iterations. In this way, the nueral netwok will provide a poor result.</p>
<h3 id=type>Type<a hidden class=anchor aria-hidden=true href=#type>#</a></h3>
<p>Generic</p>
<h3 id=existing-stage>Existing Stage<a hidden class=anchor aria-hidden=true href=#existing-stage>#</a></h3>
<p>Model Training</p>
<h3 id=effect>Effect<a hidden class=anchor aria-hidden=true href=#effect>#</a></h3>
<p>Error-prone</p>
<h3 id=example>Example<a hidden class=anchor aria-hidden=true href=#example>#</a></h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff># https://github.com/aladdinpersson/Machine-Learning-Collection/blob/a2ee9271b5280be6994660c7982d0f44c67c3b63/ML/Projects/Exploring_MNIST/networks/lenet.py

import torch
import torch.nn as nn
import torch.nn.functional as F


class LeNet(nn.Module):
    def __init__(self, in_channels, init_weights=True, num_classes=10):
        super(LeNet, self).__init__()

        self.num_classes = num_classes

        if init_weights:
            self._initialize_weights()

        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        z1 = self.conv1(x)  # 6 x 28 x 28
        a1 = F.relu(z1)  # 6 x 28 x 28
        a1 = F.max_pool2d(a1, kernel_size=2, stride=2)  # 6 x 14 x 14
        z2 = self.conv2(a1)  # 16 x 10 x 10
        a2 = F.relu(z2)  # 16 x 10 x 10
        a2 = F.max_pool2d(a2, kernel_size=2, stride=2)  # 16 x 5 x 5
        flatten_a2 = a2.view(a2.size(0), -1)
        z3 = self.fc1(flatten_a2)
        a3 = F.relu(z3)
        z4 = self.fc2(a3)
        a4 = F.relu(z4)
        z5 = self.fc3(a4)
        return z5

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode=&#34;fan_out&#34;, nonlinearity=&#34;relu&#34;)

                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)


def test_lenet():
    net = LeNet(1)
    x = torch.randn(64, 1, 32, 32)
    y = net(x)
    print(y.size())


test_lenet()
</code></pre></div><h3 id=source>Source:<a hidden class=anchor aria-hidden=true href=#source>#</a></h3>
<h4 id=paper>Paper<a hidden class=anchor aria-hidden=true href=#paper>#</a></h4>
<h4 id=grey-literature>Grey Literature<a hidden class=anchor aria-hidden=true href=#grey-literature>#</a></h4>
<h4 id=github-commit>GitHub Commit<a hidden class=anchor aria-hidden=true href=#github-commit>#</a></h4>
<h4 id=stack-overflow>Stack Overflow<a hidden class=anchor aria-hidden=true href=#stack-overflow>#</a></h4>
<h4 id=documentation>Documentation<a hidden class=anchor aria-hidden=true href=#documentation>#</a></h4>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=/tags/added/>added</a></li>
<li><a href=/tags/generic/>generic</a></li>
<li><a href=/tags/model-training/>model training</a></li>
<li><a href=/tags/error-prone/>error-prone</a></li>
</ul>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href>DSLinter - Linter for Machine Learning - Specific Code Smells</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>